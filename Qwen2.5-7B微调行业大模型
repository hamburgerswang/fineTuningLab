Qwen2.5-7Bå¾®è°ƒè¡Œä¸šå¤§æ¨¡å‹

åŸºäºQwen2.5-7B-Instructâ¼¤æ¨¡å‹è¿›â¾å¾®è°ƒå®ç°é…’åº—æ¨èå‚ç›´â¼¤æ¨¡å‹

```
# å¾®è°ƒå‰ï¼ˆå•¥éƒ½ä¼šä½†ä¸å¤Ÿä¸“ä¸šï¼‰
ç”¨æˆ·ï¼šé…’åº—æœ‰æ¸¸æ³³æ± å—ï¼Ÿ
æ¨¡å‹ï¼šå¯èƒ½å­˜åœ¨ï¼Œå»ºè®®æŸ¥è¯¢å®˜ç½‘æˆ–è‡´ç”µå‰å°ã€‚

# å¾®è°ƒåï¼ˆé…’åº—é¢†åŸŸä¸“å®¶ï¼‰
ç”¨æˆ·ï¼šé…’åº—æœ‰æ¸¸æ³³æ± å—ï¼Ÿ
æ¨¡å‹ï¼šæ˜¯çš„ï¼æˆ‘ä»¬æœ‰æ’æ¸©æ¸¸æ³³æ± ï¼Œå¼€æ”¾æ—¶é—´6:00-22:00ï¼Œéœ€æºå¸¦æˆ¿å¡ã€‚
```
![](https://rte.weiyun.baidu.com/wiki/attach/image/api/imageDownloadAddress?attachId=3ed3878290d7431592180f4fb1067336&docGuid=HiC9H1EDbTWpku "")
## **ä¸€ã€ä»€ä¹ˆæ˜¯å¤§æ¨¡å‹**
### 1ã€ä¸ä¸¥è°¨çš„ç±»â½ï¼Œé€šä¿—ç†è§£ä»€ä¹ˆæ˜¯â¼¤æ¨¡å‹å¾®è°ƒ
![](https://rte.weiyun.baidu.com/wiki/attach/image/api/imageDownloadAddress?attachId=18871206edf64218a4bfe27db953769c&docGuid=HiC9H1EDbTWpku "")
### 2ã€è½»é‡åŒ–å¾®è°ƒæµç¨‹å›¾
![](https://rte.weiyun.baidu.com/wiki/attach/image/api/imageDownloadAddress?attachId=349a21c3a3a44cf8a3b75bb052207ad4&docGuid=HiC9H1EDbTWpku "")
## äºŒã€æ­å»ºç¯å¢ƒ
é€‰æ‹© AutoDL çš„ 4090 äº‘ GPU åšä¸ºè®­ç»ƒæµ‹è¯•ç¯å¢ƒã€‚å› ä¸ºç‹¬â½´éƒ¨ç½²â¾ƒâ¼°è®­ç»ƒçš„â¼¤æ¨¡å‹ï¼Œ 4090 æ˜¯â½¬å‰æ€§ä»·â½æœ€â¾¼çš„â½…æ¡ˆ

### 1ã€ æ³¨å†ŒAutoDLå¹¶è¿›â¾å®åè®¤è¯
AutoDLå®˜â½¹é“¾æ¥ï¼š[https://www.autodl.com/](https://www.autodl.com/)

æ ¹æ®å¹³å°è¦æ±‚è¿›â¾è´¦å·æ³¨å†Œï¼Œæ³¨å†ŒæˆåŠŸç™»å½•å¹³å°è¿›â¾å®åè®¤è¯ï¼ŒæŒ‰ç…§å®˜â½…è¦æ±‚è¿›â¾è®¤è¯å³å¯

### 2ã€ æŒ‘é€‰GPU
åœ¨å®˜â½¹â¾¸â»šç‚¹å‡»ç®—â¼’å¸‚åœºèœå•è¿›â¼Šå¹¶è¿›â¾GPUé€‰æ‹©ï¼Œå‚è€ƒå¦‚ä¸‹æˆªå›¾é…ç½®è¿›â¾é€‰æ‹©å³å¯(å‚è€ƒ)

![](https://rte.weiyun.baidu.com/wiki/attach/image/api/imageDownloadAddress?attachId=fabb792168ac4502a60ad10a0c1acdba&docGuid=HiC9H1EDbTWpku "")
### 3ã€ åˆ›å»ºå®ä¾‹
GPUé€‰æ‹©ç¡®å®šåï¼Œå•å‡»nå¡å¯ç§Ÿè¿›â¼Šåˆ›å»ºå®ä¾‹â»šâ¾¯ï¼Œå¹¶æŒ‰ç…§å¦‚ä¸‹æˆªå›¾è¿›â¾é…ç½®

å…¶ä¸­ï¼Œé•œåƒé€‰æ‹©ä½¿â½¤å¼€æºçš„ç¤¾åŒºé•œåƒï¼Œè¿™â¾¥æ¨èé€‰æ‹© agiclass/fine-tuning-lab/finetune-lab-v8 ï¼Œå¹¶é€‰æ‹©æœ€æ–°ç‰ˆæœ¬ï¼Œç¤¾åŒº

ç‰ˆæœ¬é•œåƒä¸­å·²ç»é…ç½®å¥½äº†å¾®è°ƒæ‰€éœ€è¦ä¾èµ–åŒ…ç¯å¢ƒï¼Œâ¾®å¸¸â½…ä¾¿â¼¤å®¶ä½¿â½¤

![](https://rte.weiyun.baidu.com/wiki/attach/image/api/imageDownloadAddress?attachId=dabf33e3028a47bf8d3700bf4ec8b391&docGuid=HiC9H1EDbTWpku "")
å®ä¾‹åˆ›å»ºæˆåŠŸå¦‚ä¸‹æˆªå›¾æ‰€ç¤ºï¼Œå½“çŠ¶æ€ä¸ºè¿â¾ä¸­æ—¶ï¼Œè¡¨ç¤ºåˆ›å»ºå®Œæˆï¼Œå¹¶ä¸”å¼€å§‹è®¡è´¹

å¦‚æœè¦æš‚åœè®¡è´¹ï¼Œè¯·ç‚¹å‡»å…³æœºã€‚ä¸‹æ¬¡éœ€è¦ä½¿â½¤æ—¶ï¼Œå†ç‚¹å‡»å¼€æœºï¼Œè¿™â¾¥éœ€è¦æ³¨æ„å®˜â½…ç›¸å…³çš„é™åˆ¶ç­–ç•¥

![](https://rte.weiyun.baidu.com/wiki/attach/image/api/imageDownloadAddress?attachId=488082f3df7e4328a79d66cd9d1e6798&docGuid=HiC9H1EDbTWpku "")
## ä¸‰ã€å¾®è°ƒå‰â¼¯ä½œ
### 1ã€è¿æ¥å®ä¾‹
è¿™â¾¥æ¨èâ¼¤å®¶ä½¿â½¤SSHå®¢æˆ·ç«¯è½¯ä»¶è¿œç¨‹ç™»å½•åˆ°æœåŠ¡å™¨ï¼Œå¹¶åŒæ—¶è¿æ¥SFTPæœåŠ¡è¿›â¾â½‚ä»¶çš„ä¸Šä¼ ä¸‹è½½

è¿æ¥ä¿¡æ¯å¯åœ¨å¦‚ä¸‹æˆªå›¾æ‰€ç¤ºçš„åœ°â½…è·å–

![](https://rte.weiyun.baidu.com/wiki/attach/image/api/imageDownloadAddress?attachId=04844cf84dea4b2d943220f0e9613c39&docGuid=HiC9H1EDbTWpku "")
æ‰“å¼€SSHå®¢æˆ·ç«¯â¼¯å…·(è¿™â¾¥ä½¿â½¤çš„Macï¼Œâ¼¯å…·ä¸ºTermius)è¿›â¾è¿œç¨‹è¿æ¥ï¼ŒæŒ‰ç…§å¦‚ä¸‹æˆªå›¾æ‰€ç¤ºè¿›â¾é…ç½®å³å¯

![](https://rte.weiyun.baidu.com/wiki/attach/image/api/imageDownloadAddress?attachId=81f01f39e43642c6ba58029382463ba1&docGuid=HiC9H1EDbTWpku "")
### 2ã€ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹
è¿™â¾¥æ‰€éœ€çš„é¢„è®­ç»ƒæ¨¡å‹Qwen2.5-7B-Instructä»HuggingFaceä¸‹è½½ï¼Œè€ƒè™‘åˆ°å›½å†…è®¿é—®HuggingFaceâ½è¾ƒæ…¢ï¼Œè¿™â¾¥ä½¿â½¤hf-

mirrorï¼Œå®˜â½¹é“¾æ¥ [https://hf-mirror.com/Qwen/Qwen2.5-7B-Instruct](https://hf-mirror.com/Qwen/Qwen2.5-7B-Instruct)

![](https://rte.weiyun.baidu.com/wiki/attach/image/api/imageDownloadAddress?attachId=0b57aa133bef4644b50efa2506d89b42&docGuid=HiC9H1EDbTWpku "")
æ‰§â¾å¦‚ä¸‹å‘½ä»¤â¾è¿›â¾æ¨¡å‹ä¸‹è½½:

```
cd /root/autodl-tmp
git lfs install
git clone https://hf-mirror.com/Qwen/Qwen2.5-7B-Instruct
```
æ‰§â¾å®Œæˆåï¼Œè€â¼¼ç­‰å¾…ä¸‹è½½å®Œæˆå³å¯ï¼Œè¿™ä¸ªè¿‡ç¨‹éœ€è¦æŒç»­â¼¤æ¦‚**30åˆ†é’Ÿ(12:43-13:13)**å·¦å³

ä¸‹è½½å®Œæˆåï¼ŒæŸ¥çœ‹â½‚ä»¶

```
cd Qwen2.5-7B-Instruct
rm -rf .git #æ¸…é™¤æ‰.gitâ½¬å½•ï¼Œé¿å…æ•°æ®ç›˜ç©ºé—´ä¸â¾œ
```
### 3ã€ä¸Šä¼ ä»£ç 
![](https://rte.weiyun.baidu.com/wiki/attach/image/api/imageDownloadAddress?attachId=c7464d578f054d8fa5fc3c425ff99379&docGuid=HiC9H1EDbTWpku "")
å°†ä»£ç å…ˆè¿›â¾å‹ç¼©ä¸ºzipåŒ…ï¼Œé€šè¿‡SFTPè¿›â¾ä¸Šä¼ â¾„/root/autodl-tmpâ½¬å½•ä¸‹

ä¸Šä¼ æˆåŠŸåï¼Œåœ¨æœåŠ¡å™¨å‘½ä»¤â¾ç»ˆç«¯ä¸­è¿›â¾è§£å‹

```
cd /root/autodl-tmp
unzip fineTuningLab.zip
```
![](https://rte.weiyun.baidu.com/wiki/attach/image/api/imageDownloadAddress?attachId=be759039b2044874a024e24d97de4944&docGuid=HiC9H1EDbTWpku "")
## å››ã€å¾®è°ƒè¿›â¾ä¸­
### 1ã€ è®­ç»ƒ
è¿™â¾¥ä½¿â½¤loraè¿›â¾å¾®è°ƒè®­ç»ƒï¼Œå‘½ä»¤â¾ç»ˆç«¯æ‰§â¾ä¸‹â¾¯çš„å‘½ä»¤ï¼Œå¼€å§‹è®­ç»ƒ

```
cd /root/autodl-tmp/fineTuningLab/qwen2/
bash train.sh
```
```
#! /usr/bin/env bash
# æŒ‡å®šä½¿ç”¨bash shellæ‰§è¡Œæ­¤è„šæœ¬

# è®¾ç½®ä¸¥æ ¼çš„æ‰§è¡Œæ¨¡å¼ï¼š
# -e: é‡åˆ°ä»»ä½•å‘½ä»¤æ‰§è¡Œå¤±è´¥ï¼ˆè¿”å›éé›¶çŠ¶æ€ç ï¼‰æ—¶ç«‹å³é€€å‡ºè„šæœ¬
# -x: åœ¨æ‰§è¡Œæ¯ä¸ªå‘½ä»¤å‰æ‰“å°å‘½ä»¤æœ¬èº«ï¼Œä¾¿äºè°ƒè¯•
set -ex

# è®¾ç½®å­¦ä¹ ç‡
LR=2e-4

# ç”Ÿæˆå½“å‰æ—¶é—´çš„æ—¶é—´æˆ³å­—ç¬¦ä¸²ï¼Œæ ¼å¼ä¸ºï¼šå¹´æœˆæ—¥-æ—¶åˆ†ç§’
# ä¾‹å¦‚ï¼š20231215-143022
DATESTR=`date +%Y%m%d-%H%M%S`

# è®¾ç½®æœ¬æ¬¡è®­ç»ƒè¿è¡Œçš„åç§°æ ‡è¯†
RUN_NAME=hotel_qwen2

# è®¾ç½®è¾“å‡ºç›®å½•ï¼ŒåŒ…å«è¿è¡Œåç§°å’Œæ—¶é—´æˆ³ï¼Œç¡®ä¿æ¯æ¬¡è¿è¡Œéƒ½æœ‰å”¯ä¸€ç›®å½•
OUTPUT_DIR=output/${RUN_NAME}-${DATESTR}

# åˆ›å»ºè¾“å‡ºç›®å½•
# -p å‚æ•°è¡¨ç¤ºå¦‚æœç›®å½•ä¸å­˜åœ¨åˆ™åˆ›å»ºï¼Œå¦‚æœå·²å­˜åœ¨ä¹Ÿä¸ä¼šæŠ¥é”™
mkdir -p $OUTPUT_DIR

# è®¾ç½®é¢„è®­ç»ƒæ¨¡å‹çš„è·¯å¾„
MODEL_PATH="/root/autodl-tmp/Qwen2.5-7B-Instruct"

# ä½¿ç”¨CUDA_VISIBLE_DEVICESæŒ‡å®šä½¿ç”¨å“ªå¼ GPUå¡è¿›è¡Œè®­ç»ƒ
# è¿™é‡ŒæŒ‡å®šä½¿ç”¨ç¬¬0å¼ GPUå¡ï¼ˆå•å¡è®­ç»ƒï¼‰
CUDA_VISIBLE_DEVICES=0 python finetune.py \
    # å¯ç”¨è®­ç»ƒæ¨¡å¼
    --do_train \
    # å¯ç”¨è¯„ä¼°æ¨¡å¼ï¼ˆåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­è¿›è¡ŒéªŒè¯ï¼‰
    --do_eval \
    # æŒ‡å®šè®­ç»ƒæ•°æ®æ–‡ä»¶çš„è·¯å¾„ï¼ˆJSONLæ ¼å¼ï¼‰
    --train_file ../data/train.jsonl \
    # æŒ‡å®šéªŒè¯æ•°æ®æ–‡ä»¶çš„è·¯å¾„ï¼ˆJSONLæ ¼å¼ï¼‰
    --validation_file ../data/dev.jsonl \
    # æŒ‡å®šè¾“å…¥æ–‡æœ¬åœ¨æ•°æ®æ–‡ä»¶ä¸­å¯¹åº”çš„åˆ—åï¼ˆæç¤ºæ–‡æœ¬åˆ—ï¼‰
    --prompt_column context \
    # æŒ‡å®šç›®æ ‡æ–‡æœ¬åœ¨æ•°æ®æ–‡ä»¶ä¸­å¯¹åº”çš„åˆ—åï¼ˆå“åº”æ–‡æœ¬åˆ—ï¼‰
    --response_column response \
    # æŒ‡å®šè¦åŠ è½½çš„é¢„è®­ç»ƒæ¨¡å‹çš„è·¯å¾„æˆ–HuggingFaceæ¨¡å‹æ ‡è¯†
    --model_name_or_path "${MODEL_PATH}" \
    # æŒ‡å®šæ¨¡å‹è¾“å‡ºå’Œä¿å­˜çš„ç›®å½•
    --output_dir $OUTPUT_DIR \
    # è®¾ç½®è¾“å…¥æ–‡æœ¬çš„æœ€å¤§tokené•¿åº¦ï¼ˆè¶…è¿‡ä¼šè¢«æˆªæ–­ï¼‰
    --max_source_length 2048 \
    # è®¾ç½®è¾“å‡ºæ–‡æœ¬çš„æœ€å¤§tokené•¿åº¦ï¼ˆè¶…è¿‡ä¼šè¢«æˆªæ–­ï¼‰
    --max_target_length 1024 \
    # è®¾ç½®æ¯ä¸ªGPU/è®¾å¤‡çš„è®­ç»ƒæ‰¹æ¬¡å¤§å°
    --per_device_train_batch_size 1 \
    # è®¾ç½®æ¯ä¸ªGPU/è®¾å¤‡çš„è¯„ä¼°æ‰¹æ¬¡å¤§å°
    --per_device_eval_batch_size 1 \
    # è®¾ç½®æ¢¯åº¦ç´¯ç§¯æ­¥æ•°ï¼Œç”¨äºæ¨¡æ‹Ÿæ›´å¤§çš„æ‰¹æ¬¡å¤§å°
    # æœ‰æ•ˆæ‰¹æ¬¡å¤§å° = per_device_train_batch_size Ã— gradient_accumulation_steps Ã— GPUæ•°é‡
    --gradient_accumulation_steps 4 \
    # è®¾ç½®è¯„ä¼°ç­–ç•¥ï¼šæŒ‰æ­¥æ•°ï¼ˆstepsï¼‰è¿›è¡Œè¯„ä¼°
    --evaluation_strategy steps \
    # è®¾ç½®æ¯è®­ç»ƒå¤šå°‘æ­¥è¿›è¡Œä¸€æ¬¡è¯„ä¼°
    --eval_steps 300 \
    # è®¾ç½®è®­ç»ƒçš„æ€»è½®æ•°ï¼ˆepochï¼‰
    --num_train_epochs 2 \
    # è®¾ç½®æ¯è®­ç»ƒå¤šå°‘æ­¥è®°å½•ä¸€æ¬¡æ—¥å¿—
    --logging_steps 30 \
    # è®¾ç½®TensorBoardæ—¥å¿—çš„ä¿å­˜ç›®å½•
    --logging_dir $OUTPUT_DIR/logs \
    # è®¾ç½®æ¯è®­ç»ƒå¤šå°‘æ­¥ä¿å­˜ä¸€æ¬¡æ¨¡å‹checkpoint
    --save_steps 300 \
    # è®¾ç½®ä¼˜åŒ–å™¨çš„å­¦ä¹ ç‡
    --learning_rate $LR \
    # ========== LoRAç›¸å…³å‚æ•°é…ç½® ==========
    # è®¾ç½®LoRAçš„ç§©ï¼ˆrankï¼‰ï¼Œæ§åˆ¶LoRAé€‚é…å™¨çš„å¤§å°
    --lora_rank 8 \
    # è®¾ç½®LoRAçš„alphaå‚æ•°ï¼Œå½±å“é€‚é…å™¨çš„ç¼©æ”¾
    --lora_alpha 32 \
    # è®¾ç½®LoRAçš„dropoutç‡ï¼Œç”¨äºé˜²æ­¢è¿‡æ‹Ÿåˆ
    --lora_dropout 0.1 \
    # å°†æ ‡å‡†è¾“å‡ºå’Œæ ‡å‡†é”™è¯¯éƒ½é‡å®šå‘åˆ°æ–‡ä»¶ï¼ŒåŒæ—¶ä¹Ÿåœ¨ç»ˆç«¯æ˜¾ç¤º
    # teeå‘½ä»¤ï¼šåŒæ—¶è¾“å‡ºåˆ°æ–‡ä»¶å’Œç»ˆç«¯
    # 2>&1ï¼šå°†æ ‡å‡†é”™è¯¯é‡å®šå‘åˆ°æ ‡å‡†è¾“å‡º
    # |ï¼šç®¡é“ç¬¦å·ï¼Œå°†å‰ä¸€ä¸ªå‘½ä»¤çš„è¾“å‡ºä½œä¸ºåä¸€ä¸ªå‘½ä»¤çš„è¾“å…¥
    2>&1 | tee ${OUTPUT_DIR}/train.log
```
![](https://rte.weiyun.baidu.com/wiki/attach/image/api/imageDownloadAddress?attachId=c4d138fdc79c42e49ea92626e8ff57ca&docGuid=HiC9H1EDbTWpku "")
è®­ç»ƒæœŸé—´è¦ä¿æŒâ½¹ç»œè¿æ¥ï¼Œå¦åˆ™ä¼šå¯¼è‡´å‰å°è®­ç»ƒä»»åŠ¡è¿›ç¨‹è¢«killä»â½½å¯¼è‡´è®­ç»ƒå¤±è´¥

è®­ç»ƒè¿‡ç¨‹ä¸­ä¼šæœ‰è¿â¾çš„è¿›åº¦æ¡ï¼Œæ•´ä¸ªè®­ç»ƒè€—æ—¶éœ€è¦**45åˆ†é’Ÿå·¦å³**

å½“è®­ç»ƒçš„è¿›åº¦æ¡â¾›å®Œï¼Œè¯´æ˜è®­ç»ƒå®Œæˆã€‚è®­ç»ƒâ½£æˆçš„â½‚ä»¶åœ¨ /root/autodl-tmp/fine-tuning-lab/qwen2/output â½¬å½•ä¸‹ã€‚

checkpoint-nnn æ˜¯è®­ç»ƒè¿‡ç¨‹ä¸­çš„ä¸­é—´ç»“æœï¼Œnnn æ•°å­—æœ€â¼¤çš„é‚£ä¸ªæ˜¯æœ€ç»ˆç»“æœã€‚

![](https://rte.weiyun.baidu.com/wiki/attach/image/api/imageDownloadAddress?attachId=78343ac3433e43fa88375e21bdd48ea7&docGuid=HiC9H1EDbTWpku "")
### 2ã€è®­ç»ƒè¿‡ç¨‹å¯è§†åŒ–
æ–°å»ºâ¼€ä¸ªç»ˆç«¯ï¼Œä½¿â½¤tensorboardâ¼¯å…·å°†è®°å½•çš„losså¯è§†åŒ–å±•ç¤ºï¼Œç»ˆç«¯å‘½ä»¤â¾è¿â¾å¦‚ä¸‹å‘½ä»¤

tensorboard --logdir=output/hotel_qwen2-20251129-200307 --bind_all --load_fast=false

![](https://rte.weiyun.baidu.com/wiki/attach/image/api/imageDownloadAddress?attachId=823050cafc3c48b39a279b2dcf5b9669&docGuid=HiC9H1EDbTWpku "")
å…¶ä¸­ï¼Œ--logdirçš„å†…å®¹ä¸ºè®­ç»ƒè¿‡ç¨‹ä¸­â½£æˆå†…å®¹ï¼Œå¦‚output/hotel_qwen2-20251129-200307

è¿â¾æˆåŠŸåï¼Œåœ¨AutoDLå®ä¾‹ä¸­å¯ä»¥é€šè¿‡â¾ƒå®šä¹‰æœåŠ¡è®¿é—®åˆ°tensorboardå¯è§†åŒ–webâ»šï¼Œå¦‚ä¸‹æˆªå›¾æ‰€ç¤ºï¼š

![](https://rte.weiyun.baidu.com/wiki/attach/image/api/imageDownloadAddress?attachId=2f63021c0b574588b64942590b158cc8&docGuid=HiC9H1EDbTWpku "")
![](https://rte.weiyun.baidu.com/wiki/attach/image/api/imageDownloadAddress?attachId=7723fa36541d48038464d9bcea8ce89b&docGuid=HiC9H1EDbTWpku "")
## **äº”ã€å¾®è°ƒåæµ‹è¯•**
è®­ç»ƒå®Œæˆåï¼Œåœ¨æµ‹è¯•é›†ä¸Šè¿›â¾æ¨ç†æµ‹è¯•ï¼Œå¹¶è®¡ç®—å‡ºSLOTå’ŒBLEUçš„æŒ‡æ ‡

åœ¨è¿â¾æµ‹è¯•æŒ‡ä»¤å‰ï¼Œéœ€è¦ä¿®æ”¹å¯¹åº”çš„checkpointâ½‚ä»¶æ‰€åœ¨è·¯å¾„

```
cd qwen2
vim eval.sh
```
![](https://rte.weiyun.baidu.com/wiki/attach/image/api/imageDownloadAddress?attachId=ee14ce5728184312bf2baf034cec97e7&docGuid=HiC9H1EDbTWpku "")
![](https://rte.weiyun.baidu.com/wiki/attach/image/api/imageDownloadAddress?attachId=6baa97d31237405492cbc11a9443ac8c&docGuid=HiC9H1EDbTWpku "")
```
#! /usr/bin/env bash
# æŒ‡å®šä½¿ç”¨bashä½œä¸ºè„šæœ¬è§£é‡Šå™¨ï¼Œ/usr/bin/envç”¨äºè‡ªåŠ¨æŸ¥æ‰¾bashçš„è·¯å¾„

MODEL_DIR="/root/autodl-tmp/Qwen2.5-7B-Instruct"
# å®šä¹‰ç¯å¢ƒå˜é‡ï¼šåŸå§‹é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„ï¼ˆå¾®è°ƒå‰çš„åŸºç¡€Qwen2.5-7Bæ¨¡å‹ï¼‰

CHECKPOINT_DIR="output/hotel_qwen2-20251129-200307/checkpoint-2150"
# å®šä¹‰ç¯å¢ƒå˜é‡ï¼šå¾®è°ƒåçš„æ¨¡å‹æ£€æŸ¥ç‚¹è·¯å¾„
# output/hotel_qwen2-20251129-200307/ - è®­ç»ƒè¾“å‡ºç›®å½•ï¼ˆåŒ…å«æ—¶é—´æˆ³ï¼‰
# checkpoint-2150 - ç¬¬2150æ­¥ä¿å­˜çš„æ¨¡å‹æƒé‡

CUDA_VISIBLE_DEVICES=0 python evaluate.py \
# è®¾ç½®ç¯å¢ƒå˜é‡ï¼ŒæŒ‡å®šä½¿ç”¨ç¬¬0å·GPUå¡
# è¿è¡Œevaluate.pyè¯„ä¼°è„šæœ¬ï¼Œ\ è¡¨ç¤ºå‘½ä»¤ç»§ç»­åˆ°ä¸‹ä¸€è¡Œ

  --model $MODEL_DIR \
  # ä¼ é€’å‚æ•°ï¼šåŸå§‹é¢„è®­ç»ƒæ¨¡å‹çš„è·¯å¾„ï¼ˆç”¨äºå¯¹æ¯”åŸºå‡†æ€§èƒ½ï¼‰

  --ckpt $CHECKPOINT_DIR \
  # ä¼ é€’å‚æ•°ï¼šå¾®è°ƒåæ¨¡å‹çš„æ£€æŸ¥ç‚¹è·¯å¾„ï¼ˆç”¨äºè¯„ä¼°å¾®è°ƒæ•ˆæœï¼‰

  --data ../data/test.jsonl
  # ä¼ é€’å‚æ•°ï¼šæµ‹è¯•æ•°æ®æ–‡ä»¶è·¯å¾„ï¼ˆç›¸å¯¹äºå½“å‰ç›®å½•çš„ä¸Šçº§dataç›®å½•ï¼‰
```
åœ¨æ‰“å¼€çš„â½‚ä»¶ä¸­ï¼Œå°†å¯¹åº”çš„â½‚ä»¶å¤¹è·¯å¾„è°ƒæ•´ä¸ºâ¾ƒâ¼°çš„checkpointâ½‚ä»¶æ‰€åœ¨è·¯å¾„

è°ƒæ•´å®Œæˆåï¼Œä¿å­˜é€€å‡ºï¼Œç„¶åæ‰§â¾å¦‚ä¸‹å‘½ä»¤

```
bash eval.sh
```
è¿â¾ç»“æŸåï¼Œæ•´ä¸ªæµ‹è¯•è€—æ—¶éœ€è¦**13åˆ†é’Ÿå·¦å³ï¼Œ**ç»“æœå¦‚ä¸‹å›¾æ‰€ç¤º

![](https://rte.weiyun.baidu.com/wiki/attach/image/api/imageDownloadAddress?attachId=bbcca1ec11744182a4cd25db66aa97c6&docGuid=HiC9H1EDbTWpku "")
## å…­ã€æ¨¡å‹ä½¿â½¤
ä½¿ç”¨wcdï¼ˆweaviate cloudï¼‰å‘é‡åº“å’Œhuggingfaceæ¨¡å‹åšåˆ†è¯

wcdï¼š[https://console.weaviate.cloud/cluster-details/9529e444-22c7-4d7a-8493-0367812d5688](https://console.weaviate.cloud/cluster-details/9529e444-22c7-4d7a-8493-0367812d5688)

### 1ã€åˆ›å»ºwcdå¹¶å¯¼å…¥æ•°æ®
```
import json

from dotenv import load_dotenv
load_dotenv("api_keys.env")
import os
import re
import weaviate
from weaviate.classes.init import Auth



def rrf(rankings, k=60):
    if not isinstance(rankings, list):
        raise ValueError("Rankings should be a list.")
    scores = dict()
    for ranking in rankings:
        if not ranking:  # å¦‚æœrankingä¸ºç©ºï¼Œè·³è¿‡å®ƒ
            continue
        for i, doc in enumerate(ranking):
            if not isinstance(doc, dict):
                raise ValueError("Each item should be dict type.")
            doc_id = doc.get('hotel_id', None)
            if doc_id is None:
                raise ValueError("Each item should have 'hotel_id' key.")
            if doc_id not in scores:
                scores[doc_id] = (0, doc)
            scores[doc_id] = (scores[doc_id][0] + 1 / (k + i), doc)

    sorted_scores = sorted(scores.values(), key=lambda x: x[0], reverse=True)
    return [item[1] for item in sorted_scores]


class HotelDB():
    def __init__(self, url="http://8.217.22.255:6500"):
        client = weaviate.connect_to_weaviate_cloud(
            cluster_url="https://ipu4fofq3cudvfcc1ek7a.c0.asia-southeast1.gcp.weaviate.cloud",
            auth_credentials=Auth.api_key(os.getenv("WEAVIATE_API_KEY")),
            headers={
                "X-OpenAI-Api-Key": os.getenv("OPENAI_API_KEY"),
                "X-HuggingFace-Api-Key": os.getenv("HUGGINGFACE_API_KEY")},
            additional_config=weaviate.config.AdditionalConfig(
                timeout=weaviate.config.Timeout(init=10)
            )
        )
        self.client = client

    def insert(self):
        """ç”¨ v4 æ–¹å¼åˆ›å»º Hotel Collection å¹¶å¯¼å…¥æ•°æ®"""
        from weaviate.classes.config import Configure, Property, DataType, Tokenization

        collection_name = "Hotel"

        # ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨ç¡®ä¿è¿æ¥å…³é—­
        with self.client as client:
            # åˆ é™¤å·²å­˜åœ¨çš„ Collection
            if client.collections.exists(collection_name):
                print(f"âš ï¸ Collection '{collection_name}' å·²å­˜åœ¨ï¼Œæ­£åœ¨åˆ é™¤...")
                client.collections.delete(collection_name)

            # åˆ›å»ºæ–° Collection
            client.collections.create(
                name=collection_name,
                description="hotel info",
                # vectorizer_config=Configure.Vectorizer.text2vec_huggingface(
                #     model="sentence-transformers/all-MiniLM-L6-v2",  # å…è´¹ã€è½»é‡ã€ä¸­æ–‡å¯ç”¨
                #     wait_for_model=False,
                #     use_gpu=False,
                #     vectorize_collection_name=False,
                # ),
                vectorizer_config=Configure.Vectorizer.text2vec_huggingface(
                    model="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",  # å¤šè¯­è¨€ï¼Œæ”¯æŒä¸­æ–‡
                    wait_for_model=False,
                    use_gpu=False,
                    vectorize_collection_name=False,
                ),
                properties=[
                    # hotel_id
                    Property(
                        name="hotel_id",
                        data_type=DataType.INT,
                        description="id of hotel"
                    ),
                    # _nameï¼ˆç”¨äº BM25 æœç´¢ï¼‰
                    Property(
                        name="_name",
                        data_type=DataType.TEXT,
                        description="name of hotel (tokenized for search)",
                        index_filterable=True,
                        index_searchable=True,
                        tokenization=Tokenization.WHITESPACE,  # âœ… ä¿®å¤ç‚¹1
                        # skip_vectorization=True,
                    ),
                    # nameï¼ˆåŸå§‹å€¼ï¼‰
                    Property(
                        name="name",
                        data_type=DataType.TEXT,
                        description="type of hotel",
                        # skip_vectorization=True,
                    ),
                    # type
                    Property(
                        name="type",
                        data_type=DataType.TEXT,
                        description="type of hotel",
                        # skip_vectorization=True,
                    ),
                    # _addressï¼ˆç”¨äº BM25 æœç´¢ï¼‰
                    Property(
                        name="_address",
                        data_type=DataType.TEXT,
                        description="address of hotel (tokenized for search)",
                        index_filterable=True,
                        index_searchable=True,
                        tokenization=Tokenization.WHITESPACE,  # âœ… ä¿®å¤ç‚¹1
                        # skip_vectorization=True,
                    ),
                    # addressï¼ˆåŸå§‹å€¼ï¼‰
                    Property(
                        name="address",
                        data_type=DataType.TEXT,
                        description="type of hotel",
                        # skip_vectorization=True,
                    ),
                    # subway
                    Property(
                        name="subway",
                        data_type=DataType.TEXT,
                        description="nearby subway",
                        # skip_vectorization=True,
                    ),
                    # phone
                    Property(
                        name="phone",
                        data_type=DataType.TEXT,
                        description="phone of hotel",
                        # skip_vectorization=True,
                    ),
                    # price
                    Property(
                        name="price",
                        data_type=DataType.NUMBER,
                        description="price of hotel"
                    ),
                    # rating
                    Property(
                        name="rating",
                        data_type=DataType.NUMBER,
                        description="rating of hotel"
                    ),
                    # facilitiesï¼ˆå”¯ä¸€è¢«å‘é‡åŒ–çš„æ–‡æœ¬å­—æ®µï¼‰
                    Property(
                        name="facilities",
                        data_type=DataType.TEXT,
                        description="facilities provided",
                        index_filterable=True,
                        index_searchable=True,
                        skip_vectorization=False,  # å…è®¸ OpenAI å‘é‡åŒ–
                    ),
                ]
            )
            print(f"âœ… Collection '{collection_name}' åˆ›å»ºæˆåŠŸ")

            # ä¸‹è½½å¹¶åŠ è½½æ•°æ®
            import requests
            import json
            from tqdm import tqdm

            url = "https://raw.githubusercontent.com/agiclass/hotel-chatbot/main/data/hotel.json"
            if not os.path.exists("hotel.json"):
                print("ğŸ“¥ æ­£åœ¨ä¸‹è½½ hotel.json...")
                try:
                    response = requests.get(url, timeout=30)  # å¢åŠ è¶…æ—¶æ—¶é—´
                    response.raise_for_status()
                    with open("hotel.json", "w", encoding="utf-8") as f:
                        json.dump(response.json(), f, ensure_ascii=False, indent=2)
                    print("âœ… ä¸‹è½½å®Œæˆ")
                except Exception as e:
                    print(f"âŒ ä¸‹è½½å¤±è´¥: {e}")
                    return  # å¦‚æœä¸‹è½½å¤±è´¥ï¼Œæå‰é€€å‡ºï¼Œé¿å…åç»­æ“ä½œ
            else:
                print("ğŸ“ hotel.json å·²å­˜åœ¨")

            with open("hotel.json", "r", encoding="utf-8") as f:
                hotels = json.load(f)

            # æ‰¹é‡å¯¼å…¥æ•°æ®
            collection = client.collections.get(collection_name)
            print(f"ğŸ“¤ æ­£åœ¨å¯¼å…¥ {len(hotels)} æ¡é…’åº—æ•°æ®...")

            with collection.batch.dynamic() as batch:
                for hotel in tqdm(hotels, desc="å¯¼å…¥è¿›åº¦"):
                    batch.add_object(
                        properties=hotel,
                        uuid=weaviate.util.generate_uuid5(hotel, collection_name)
                    )

            # æ£€æŸ¥å¤±è´¥å¯¹è±¡
            if collection.batch.failed_objects:
                print(f"âš ï¸ å¯¼å…¥å¤±è´¥æ•°é‡: {len(collection.batch.failed_objects)}")
                print("ç¬¬ä¸€ä¸ªå¤±è´¥å¯¹è±¡é”™è¯¯:", collection.batch.failed_objects[0].message)
            else:
                print("âœ… æ‰€æœ‰æ•°æ®å¯¼å…¥æˆåŠŸï¼")

    def search(self, dsl, name="Hotel", limit=1):
        # æ¸…ç† DSL
        dsl = {k: v for k, v in dsl.items() if v is not None}
        _limit = limit + 10
        output_fields = ["hotel_id", "name", "type", "address", "phone", "subway", "facilities", "price", "rating"]

        collection = self.client.collections.get(name)

        # === 1. æ„å»º filters (v4) ===
        from weaviate.classes.query import Filter
        filters = None

        if "type" in dsl:
            filters = Filter.by_property("type").equal(dsl["type"])
        if "price_range_lower" in dsl:
            f = Filter.by_property("price").greater_than(dsl["price_range_lower"])
            filters = f if filters is None else filters & f
        if "price_range_upper" in dsl:
            f = Filter.by_property("price").less_than(dsl["price_range_upper"])
            filters = f if filters is None else filters & f
        if "rating_range_lower" in dsl:
            f = Filter.by_property("rating").greater_than(dsl["rating_range_lower"])
            filters = f if filters is None else filters & f
        if "rating_range_upper" in dsl:
            f = Filter.by_property("rating").less_than(dsl["rating_range_upper"])
            filters = f if filters is None else filters & f

        candidates = []

        # === 2. å‘é‡æœç´¢ (facilities) ===
        if "facilities" in dsl and dsl["facilities"]:
            query_text = "é…’åº—æä¾›ï¼š" + "ï¼Œ".join(dsl["facilities"])
            res = collection.query.near_text(
                query=query_text,
                limit=_limit,
                filters=filters,
                return_properties=output_fields
            )
            candidates = [obj.properties for obj in res.objects]

        # === 3. å…³é”®è¯æœç´¢ (name) ===
        elif "name" in dsl and dsl["name"]:
            import re
            clean_name = " ".join(re.findall(r"[\w\-]+", dsl["name"]))
            res = collection.query.bm25(
                query=clean_name,
                query_properties=["_name"],
                limit=_limit,
                filters=filters,
                return_properties=output_fields
            )
            candidates = [obj.properties for obj in res.objects]

        # === 4. å…³é”®è¯æœç´¢ (address) ===
        elif "address" in dsl and dsl["address"]:
            import re
            clean_addr = " ".join(re.findall(r"[\w\-]+", dsl["address"]))
            res = collection.query.bm25(
                query=clean_addr,
                query_properties=["_address"],
                limit=_limit,
                filters=filters,
                return_properties=output_fields
            )
            candidates = [obj.properties for obj in res.objects]

        # === 5. çº¯ç»“æ„åŒ–è¿‡æ»¤ ===
        else:
            res = collection.query.fetch_objects(
                limit=_limit,
                filters=filters,
                return_properties=output_fields
            )
            candidates = [obj.properties for obj in res.objects]

        # === 6. æ’åº ===
        if "sort.slot" in dsl:
            reverse = dsl.get("sort.ordering") == "descend"
            slot = dsl["sort.slot"]
            candidates = sorted(candidates, key=lambda x: x.get(slot, 0), reverse=reverse)

        # === 7. name åè¿‡æ»¤ï¼ˆå­ä¸²åŒ¹é…ï¼‰===
        if "name" in dsl:
            filtered = []
            for r in candidates:
                if dsl["name"] in r.get("name", ""):
                    filtered.append(r)
            candidates = filtered

        return candidates[:limit]


if __name__ == "__main__":
    db = HotelDB()
    try:
        # ä½ çš„é€»è¾‘ï¼Œæ¯”å¦‚ db.search(...)
        result = db.search({"facilities": ["wifi"]}, limit=3)
        print(json.dumps(result, ensure_ascii=False, indent=2))
    finally:
        # ç¡®ä¿è¿æ¥è¢«å…³é—­
        db.client.close()

```
![](https://rte.weiyun.baidu.com/wiki/attach/image/api/imageDownloadAddress?attachId=45e56cfc1d094631ba989a066dcbebac&docGuid=HiC9H1EDbTWpku "")
è¿è¡ŒæŸ¥çœ‹æ•°æ®

![](https://rte.weiyun.baidu.com/wiki/attach/image/api/imageDownloadAddress?attachId=064d787a935045af9afcff08363cd447&docGuid=HiC9H1EDbTWpku "")
### 2ã€ä½¿ç”¨gradioæ¸²æŸ“å¯è§†åŒ–é¡µé¢
```
import warnings
warnings.filterwarnings('ignore')
import sys
sys.path.append('../qwen2')
import json
import torch
import argparse
import gradio as gr
import pandas as pd
from db_client import HotelDB
from evaluate import load_model
from data_preprocess import build_prompt, parse_json

# init gloab variables
parser = argparse.ArgumentParser()
parser.add_argument("--model", type=str, default=None, required=True, help="main model weights")
parser.add_argument("--ckpt", type=str, default=None, required=True, help="The checkpoint path")
args = parser.parse_args()

db = HotelDB()
tokenizer, model = load_model(args.model, args.ckpt)

def get_completion(prompt):
    inputs = tokenizer([prompt], return_tensors="pt").to("cuda")
    with torch.no_grad():
        outputs = model.generate(**inputs, max_new_tokens=1024)
        response = tokenizer.decode(outputs[:,inputs['input_ids'].shape[1]:][0], skip_special_tokens=True)
    return response

def remove_search_history(context):
    i = 0
    while i < len(context):
        if context[i]['role'] in ['search','return']:
            del context[i]
        else:
            i += 1

def chat(user_input, chatbot, context, search_field, return_field):
    context.append({'role':'user','content':user_input})
    response = get_completion(build_prompt(context))
    #print(response)
    # åˆ¤æ–­ä»¥searchå‘½ä»¤å¼€å¤´æ—¶å»æ‰§è¡Œæœç´¢
    if "search" in response:
        # å–å‡ºæœ€æ–°ä¸€æ¡ 'search' åé¢çš„jsonæŸ¥è¯¢æ¡ä»¶
        search_query = parse_json(response)
        if search_query is not None:
            search_field = json.dumps(search_query,indent=4,ensure_ascii=False)
            remove_search_history(context)
            context.append({'role':'search','arguments':search_query})
            # è°ƒç”¨é…’åº—æŸ¥è¯¢æ¥å£
            try:
                return_field = db.search(search_query, limit=3)
            finally:
                db.client.close()

            context.append({'role':'return','records':return_field})
            keys = []
            if return_field:
                keys = ['name', 'address', 'phone', 'price', 'rating', 'subway', 'type', 'facilities']
            data = {key: [item[key] for item in return_field] for key in keys}
            data = data or {"hotel": []}
            return_field = pd.DataFrame(data)
            # å°†æŸ¥è¯¢ç»“æœå‘ç»™LLMï¼Œå†æ¬¡é‚£ä¹ˆè®©LLMç”Ÿæˆå›å¤
            response = get_completion(build_prompt(context))

    reply = response.replace("assistant", "")
    chatbot.append((user_input, reply))
    context.append({'role':'assistant','content':reply})
    return "", chatbot, context, search_field, return_field

def reset_state():
    return [], [], "", "", None

def main():
    with gr.Blocks() as demo:
        gr.HTML("""<h1 align="center">Hotel Chatbot (Qwen2 LoRA)</h1>""")

        with gr.Row():
            with gr.Column(scale=2):
                chatbot = gr.Chatbot()
            with gr.Column(scale=2):
                gr.HTML("""<h4>Search</h4>""")
                search_field = gr.Textbox(show_label=False, placeholder="search...", lines=8)
                user_input = gr.Textbox(show_label=False, placeholder="è¾“å…¥æ¡†...", lines=2)
                with gr.Row():
                    submitBtn = gr.Button("æäº¤", variant="primary")
                    emptyBtn = gr.Button("æ¸…ç©º")

        with gr.Row():
            with gr.Column():
                gr.HTML("""<h4>Return</h4>""")
                return_field = gr.Dataframe()

        context = gr.State([])

        submitBtn.click(chat, [user_input, chatbot, context, search_field, return_field],
                        [user_input, chatbot, context, search_field, return_field])
        emptyBtn.click(reset_state, outputs=[chatbot, context, user_input, search_field, return_field])

    demo.queue().launch(share=False, server_name='0.0.0.0', server_port=6006, inbrowser=True)

if __name__ == "__main__":
    main()

```
```
import json
import torch
import argparse
from tqdm import tqdm
from peft import PeftModel
from transformers import AutoTokenizer, AutoModelForCausalLM
from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction
from data_preprocess import build_prompt, parse_json

def load_model(model_path, checkpoint_path):
    tokenizer = AutoTokenizer.from_pretrained(model_path)
    model = AutoModelForCausalLM.from_pretrained(model_path, torch_dtype=torch.bfloat16)
    model = PeftModel.from_pretrained(model, model_id=checkpoint_path).to("cuda").eval()
    return tokenizer, model

class Evaluator:
    def __init__(self,tokenizer,model,data_path):
        self.tokenizer = tokenizer
        self.model = model
        self.data_path = data_path

    def slot_accuracy(self, pred, label):
        correct = 0
        if pred is not None:
            for k, v in pred.items():
                if v is None:
                    continue
                if label and k in label:
                    if not isinstance(v,list):
                        correct += int(v==label[k])
                    else:
                        for t in v:
                            correct += int(t in label[k])
        pred_slots = sum(len(v) if isinstance(v, list) else 1 for v in pred.values()) if pred else 0
        true_slots = sum(len(v) if isinstance(v, list) else 1 for v in label.values()) if label else 0
        return correct, pred_slots, true_slots

    def bleu4(self, pred, label):
        pred = pred.strip()
        label = label.strip()

        hypothesis = list(pred)
        reference = list(label)

        if len(hypothesis) == 0 or len(reference) == 0:
            return 0

        bleu_score = sentence_bleu([reference], hypothesis, smoothing_function=SmoothingFunction().method3)
        return bleu_score

    def compute_metrics(self):
        score_dict = { "slot_P": 0.0, "slot_R": 0.0, "slot_F1": 0.0 }
        bleu_scores = []
        true_slot_count = 0
        pred_slot_count = 0
        correct_slot_count = 0

        with open(self.data_path, "r", encoding="utf-8") as f:
            test_dataset = [json.loads(line) for line in f]

        for item in tqdm(test_dataset):
            template = build_prompt(item["context"])
            inputs = self.tokenizer([template], return_tensors="pt").to("cuda")
            with torch.no_grad():
                outputs = self.model.generate(**inputs, max_new_tokens=1024)
                response = self.tokenizer.decode(outputs[:,inputs['input_ids'].shape[1]:][0], skip_special_tokens=True)
            label = json.loads(item["response"])
            if label["role"] == "search":
                try:
                    preds = parse_json(response)
                except:
                    preds = {}
                truth = label["arguments"]
                correct, pred_slots, true_slots = self.slot_accuracy(preds, truth)
                true_slot_count += true_slots
                pred_slot_count += pred_slots
                correct_slot_count += correct
            else:
                response = response.replace("assistant","")
                bleu_scores.append(self.bleu4(response, label['content']))

        score_dict["slot_P"] = float(correct_slot_count/pred_slot_count) if pred_slot_count > 0 else 0
        score_dict["slot_R"] = float(correct_slot_count/true_slot_count) if true_slot_count > 0 else 0
        score_dict["slot_F1"] = 2*score_dict["slot_P"]*score_dict["slot_R"]/(score_dict["slot_P"]+score_dict["slot_R"]) if (score_dict["slot_P"]+score_dict["slot_R"]) > 0 else 0
        score_dict["bleu-4"] = sum(bleu_scores) / len(bleu_scores)
        for k, v in score_dict.items():
            score_dict[k] = round(v * 100, 4)
        print(f"score dict: {score_dict}")


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--model", type=str, default=None, required=True, help="main model weights")
    parser.add_argument("--ckpt", type=str, default=None, required=True, help="The checkpoint path")
    parser.add_argument("--data", type=str, default=None, required=True, help="The dataset file path")
    args = parser.parse_args()

    tokenizer, model = load_model(args.model, args.ckpt)
    evaluator = Evaluator(tokenizer, model, args.data)
    evaluator.compute_metrics()

```
```
import json
from torch.utils.data import Dataset

# å®šä¹‰ä¸€ä¸ªåä¸º InputOutputDataset çš„æ–°ç±»ï¼Œå®ƒç»§æ‰¿è‡ª Dataset ç±»ã€‚è¿™ä½¿å¾—æˆ‘ä»¬çš„æ•°æ®é›†èƒ½å¤Ÿä¸ PyTorch çš„æ•°æ®åŠ è½½å™¨å…¼å®¹ï¼Œæ”¯æŒæ‰¹å¤„ç†å’Œå…¶ä»–æ•°æ®åŠ è½½åŠŸèƒ½
class InputOutputDataset(Dataset):
    # å®šä¹‰ç±»çš„åˆå§‹åŒ–æ–¹æ³•ï¼Œæ¥æ”¶ä¸‰ä¸ªå‚æ•°ï¼šdataï¼ˆæ•°æ®é›†ï¼‰ã€tokenizerï¼ˆåˆ†è¯å™¨ï¼‰ã€argsï¼ˆå…¶ä»–å‚æ•°é…ç½®ï¼‰
    def __init__(self, data, tokenizer, args):
        # è°ƒç”¨çˆ¶ç±» Dataset çš„åˆå§‹åŒ–æ–¹æ³•ï¼Œä»¥ç¡®ä¿æ•°æ®é›†æ­£ç¡®åˆå§‹åŒ–ã€‚è¿™æ˜¯ç»§æ‰¿ç±»çš„æ ‡å‡†åšæ³•
        super(InputOutputDataset, self).__init__()
        self.data = data
        self.tokenizer = tokenizer
        self.prompt_column = args.prompt_column
        self.response_column = args.response_column
        self.max_source_length = args.max_source_length
        self.max_target_length = args.max_target_length

    # ç”¨äºè¿”å›æ•°æ®é›†çš„é•¿åº¦ï¼Œæ»¡è¶³ Python çš„é•¿åº¦åè®®
    def __len__(self):
        return len(self.data)

    # é€šè¿‡ç´¢å¼•è®¿é—®æ•°æ®é›†ä¸­çš„æ ·æœ¬
    def __getitem__(self, i):
        item = self.data[i]
        # add_special_tokens ä¸åœ¨å¼€å¤´åŠ  special_tokens
        # è°ƒç”¨åˆ†è¯å™¨ï¼Œå¯¹æ„å»ºçš„æç¤ºæ–‡æœ¬è¿›è¡Œç¼–ç 
        context = self.tokenizer(
            build_prompt(item[self.prompt_column]), 
            max_length=self.max_source_length, 
            add_special_tokens=False)
        response = self.tokenizer(
            build_response(item[self.response_column]), 
            max_length=self.max_target_length, 
            add_special_tokens=False)
        # å°†ä¸Šä¸‹æ–‡å’Œå“åº”çš„ input_ids è¿æ¥èµ·æ¥ï¼Œå½¢æˆä¸€ä¸ªå®Œæ•´çš„è¾“å…¥åºåˆ—
        input_ids = context["input_ids"] + response["input_ids"]
        # å°†ä¸Šä¸‹æ–‡å’Œå“åº”çš„æ³¨æ„åŠ›æ©ç è¿æ¥èµ·æ¥ï¼Œç¡®ä¿æ¨¡å‹åœ¨è®¡ç®—æ³¨æ„åŠ›æ—¶èƒ½å¤Ÿæ­£ç¡®åœ°å…³æ³¨è¾“å…¥åºåˆ—çš„ç›¸å…³éƒ¨åˆ†
        attention_mask = context["attention_mask"] + response["attention_mask"]
        # åˆ›å»ºæ ‡ç­¾æ•°ç»„ï¼Œæ ‡è®°ä¸Šä¸‹æ–‡éƒ¨åˆ†ä¸º -100ï¼ˆè¡¨ç¤ºåœ¨è®¡ç®—æŸå¤±æ—¶å¿½ç•¥ï¼‰ï¼Œè€Œå“åº”éƒ¨åˆ†ä½¿ç”¨çœŸå®çš„ input_ids
        labels = [-100] * len(context["input_ids"]) + response["input_ids"]
        # ç¡®ä¿è¾“å…¥ ID å’Œæ ‡ç­¾çš„é•¿åº¦ä¸€è‡´ï¼Œå¦‚æœä¸ä¸€è‡´ï¼Œå°†æŠ›å‡ºæ–­è¨€é”™è¯¯ï¼Œæä¾›é•¿åº¦ä¿¡æ¯ä»¥ä¾¿è°ƒè¯•
        assert len(input_ids) == len(labels), f"length mismatch: {len(input_ids)} vs {len(labels)}"
        # è¿”å›ä¸€ä¸ªå­—å…¸ï¼Œå…¶ä¸­åŒ…å«ç¼–ç åçš„è¾“å…¥ IDã€æ³¨æ„åŠ›æ©ç å’Œæ ‡ç­¾ï¼Œä¾›æ¨¡å‹è®­ç»ƒä½¿ç”¨
        return {
            "input_ids": input_ids,
            "attention_mask": attention_mask,
            "labels": labels
        }

# ç”¨äºæ„å»ºæç¤ºå­—ç¬¦ä¸²
def build_prompt(context):
    # æ£€æŸ¥ä¸Šä¸‹æ–‡æ˜¯å¦ä¸ºå­—ç¬¦ä¸²ç±»å‹ï¼Œå¦‚æœæ˜¯ï¼Œåˆ™å°†å…¶è§£æä¸º JSON å¯¹è±¡
    if isinstance(context,str):
        context = json.loads(context)
    # åˆå§‹åŒ–ä¸€ä¸ªç©ºå­—ç¬¦ä¸²ï¼Œç”¨äºå­˜å‚¨æ„å»ºçš„æç¤ºæ–‡æœ¬
    prompt = ''
    # éå†ä¸Šä¸‹æ–‡ä¸­çš„æ¯ä¸ªå¯¹è¯è½®æ¬¡
    for turn in context:
        # æ£€æŸ¥è§’è‰²æ˜¯å¦ä¸ºç”¨æˆ·æˆ–åŠ©æ‰‹
        if turn["role"] in ["user","assistant"]:
            # å°†å½“å‰å¯¹è¯çš„è§’è‰²å’Œå†…å®¹ä»¥æŒ‡å®šæ ¼å¼æ·»åŠ åˆ°æç¤ºå­—ç¬¦ä¸²ä¸­
            prompt += f'<|im_start|>{turn["role"]}\n{turn["content"]}<|im_end|>\n'
        # å¤„ç†è§’è‰²ä¸ä¸ºç”¨æˆ·æˆ–åŠ©æ‰‹çš„æƒ…å†µ
        else:
            # æ£€æŸ¥è§’è‰²æ˜¯å¦ä¸º search
            if turn["role"] == "search":
                # æå–æœç´¢å‚æ•°å¯¹è±¡
                obj = turn["arguments"]
                # è¿‡æ»¤æ‰å€¼ä¸º None çš„å‚æ•°ï¼Œåˆ›å»ºæ–°çš„å­—å…¸
                filtered_obj = {k: v for k, v in obj.items() if v is not None}
                # æ·»åŠ æœç´¢çš„å¼€å§‹æ ‡è®°
                prompt += '<|im_start|>search\n'
                # å°†è¿‡æ»¤åçš„æœç´¢å‚æ•°è½¬æ¢ä¸ºæ ¼å¼åŒ–çš„ JSON å­—ç¬¦ä¸²ï¼Œå¹¶æ·»åŠ åˆ°æç¤ºä¸­
                prompt += json.dumps(filtered_obj,indent=4,ensure_ascii=False)
            # å¤„ç†è§’è‰²ä¸ºè¿”å›ï¼ˆreturnï¼‰çš„æƒ…å†µ
            else:
                # æå–è®°å½•æ•°æ®
                obj = turn["records"]
                # æ·»åŠ è¿”å›æ•°æ®çš„ç»“æŸæ ‡è®°ï¼Œå®Œæˆè¿™ä¸€è½®å¯¹è¯çš„æç¤ºæ„å»º
                prompt += '<|im_start|>return\n'
                prompt += json.dumps(obj,indent=4,ensure_ascii=False)
            prompt += '<|im_end|>\n'
    # è¿”å›æ„å»ºå¥½çš„å®Œæ•´æç¤ºå­—ç¬¦ä¸²
    return prompt

# ç”¨äºæ„å»ºå“åº”å­—ç¬¦ä¸²
def build_response(response):
    # æ£€æŸ¥å“åº”æ˜¯å¦ä¸ºå­—ç¬¦ä¸²ç±»å‹ï¼Œè‹¥æ˜¯åˆ™è§£æä¸º JSON å¯¹è±¡
    if isinstance(response,str):
        response = json.loads(response)
    # åˆ¤æ–­è§’è‰²æ˜¯å¦ä¸ºåŠ©æ‰‹
    if response["role"] == "assistant":
        # æ„å»ºåŠ©æ‰‹çš„å“åº”å­—ç¬¦ä¸²ï¼Œæ ¼å¼ä¸º
        return '<|im_start|>assistant\n' + response["content"] + '<|im_end|>'
    # å¤„ç†è§’è‰²ä¸æ˜¯åŠ©æ‰‹çš„æƒ…å†µ
    else:
        # æå–å“åº”ä¸­çš„å‚æ•°å¯¹è±¡
        obj = response["arguments"]
        # è¿‡æ»¤æ‰å€¼ä¸º None çš„å‚æ•°ï¼Œåˆ›å»ºæ–°çš„å­—å…¸
        filtered_obj = {k: v for k, v in obj.items() if v is not None}
        # æ„å»ºæœç´¢çš„å“åº”å­—ç¬¦ä¸²ï¼Œæ ¼å¼ä¸º
        return '<|im_start|>search\n' + json.dumps(filtered_obj,indent=4,ensure_ascii=False) + '<|im_end|>'

# æ¥å—ä¸€ä¸ªå­—ç¬¦ä¸²å¹¶å°è¯•ä»ä¸­è§£æå‡º JSON å¯¹è±¡
def parse_json(string):
    # åˆå§‹åŒ–æœç´¢èµ·å§‹ä½ç½®ä¸º 0
    search_pos = 0
    # å¯»æ‰¾å­—ç¬¦ä¸²ä¸­ç¬¬ä¸€ä¸ª { çš„ä½ç½®ï¼Œç”¨äºæ ‡è¯† JSON å¯¹è±¡çš„å¼€å§‹
    start = string.find('{', search_pos)
    # å¦‚æœæœªæ‰¾åˆ° {ï¼Œè¿”å› None
    if start == -1:
        return None
    # ä»æ‰¾åˆ°çš„ { ä½ç½®å¼€å§‹ï¼Œå¯»æ‰¾æœ€åä¸€ä¸ª } çš„ä½ç½®ï¼Œæ ‡è¯† JSON å¯¹è±¡çš„ç»“æŸ
    end = string.rfind('}', start)
    # å¦‚æœæœªæ‰¾åˆ° }ï¼Œè¿”å› None
    if end == -1:
        return None
    # æå–å‡º JSON å­—ç¬¦ä¸²ï¼Œä»æ‰¾åˆ°çš„ { åˆ° } çš„éƒ¨åˆ†
    json_string = string[start:end + 1]
    try:
        # å°†å­—ç¬¦ä¸²è§£æä¸º Python å¯¹è±¡
        obj = json.loads(json_string)
        return obj
    except json.JSONDecodeError:
        return None

```
### 3ã€åœ¨æ²™ç›’ç¯å¢ƒè·‘å¹¶ä½¿ç”¨autodlçš„è‡ªå®šä¹‰æœåŠ¡è¿›è¡Œå¯è§†åŒ–
ä½¿â½¤æä¾›çš„web_demoä»£ç è¿›â¾æ¨¡å‹ä½¿â½¤æµ‹è¯•ï¼Œæµ‹è¯•å‰éœ€è¦ä¿®æ”¹ä½¿â½¤è®­ç»ƒåçš„æ¨¡å‹ï¼Œç„¶åæ‰§â¾å¦‚ä¸‹å‘½ä»¤

```
cd /root/autodl-tmp/fineTuningLab/web_demo
vim qwen2_lora.sh
```
```
#! /usr/bin/env bash
# æŒ‡å®šä½¿ç”¨bashä½œä¸ºè„šæœ¬è§£é‡Šå™¨ï¼Œ/usr/bin/envä¼šä»PATHç¯å¢ƒå˜é‡ä¸­æŸ¥æ‰¾bashçš„ä½ç½®

MODEL_DIR="/root/autodl-tmp/Qwen2.5-7B-Instruct"
# å®šä¹‰ç¯å¢ƒå˜é‡ï¼šåŸå§‹é¢„è®­ç»ƒçš„åŸºç¡€æ¨¡å‹è·¯å¾„
# è¿™æ˜¯å¾®è°ƒå‰çš„Qwen2.5-7B-Instructæ¨¡å‹ï¼Œä½œä¸ºå¯¹è¯ç”Ÿæˆçš„åŸºå‡†æ¨¡å‹

CHECKPOINT_DIR="../qwen2/output/hotel_qwen2-20251129-200307/checkpoint-2150"
# å®šä¹‰ç¯å¢ƒå˜é‡ï¼šå¾®è°ƒåçš„æ¨¡å‹æ£€æŸ¥ç‚¹è·¯å¾„
# ../qwen2/ - ç›¸å¯¹è·¯å¾„ï¼ŒæŒ‡å‘ä¸Šä¸€çº§ç›®å½•ä¸­çš„qwen2æ–‡ä»¶å¤¹
# output/hotel_qwen2-20251129-200307/ - è®­ç»ƒè¾“å‡ºç›®å½•ï¼ˆåŒ…å«æ—¶é—´æˆ³20:03:07ï¼‰
# checkpoint-2150 - ç¬¬2150æ­¥ä¿å­˜çš„å¾®è°ƒæ¨¡å‹æƒé‡

CUDA_VISIBLE_DEVICES=0 python webui_qwen2.py \
# è®¾ç½®ç¯å¢ƒå˜é‡ï¼ŒæŒ‡å®šä½¿ç”¨ç¬¬0å·GPUå¡è¿›è¡Œæ¨ç†
# è¿è¡Œwebui_qwen2.pyè„šæœ¬ï¼ˆWebç”¨æˆ·ç•Œé¢ï¼‰ï¼Œ\ è¡¨ç¤ºå‘½ä»¤å»¶ç»­åˆ°ä¸‹ä¸€è¡Œ

    --model $MODEL_DIR \
    # ä¼ é€’å‚æ•°ï¼šåŸå§‹é¢„è®­ç»ƒæ¨¡å‹çš„è·¯å¾„
    # ç”¨äºWebç•Œé¢ä¸­å¯èƒ½çš„åŸºç¡€æ¨¡å‹å¯¹æ¯”æˆ–å›é€€åŠŸèƒ½
    
    --ckpt $CHECKPOINT_DIR
    # ä¼ é€’å‚æ•°ï¼šå¾®è°ƒåæ¨¡å‹çš„æ£€æŸ¥ç‚¹è·¯å¾„
    # Webç•Œé¢å°†ä¸»è¦ä½¿ç”¨è¿™ä¸ªå¾®è°ƒåçš„æ¨¡å‹è¿›è¡Œå¯¹è¯äº¤äº’
```
ä¿®æ”¹å¦‚ä¸‹ä¸¤å¤„å‚æ•°ï¼Œæ ¹æ®å®é™…æƒ…å†µè¿›â¾æ›¿æ¢

![](https://rte.weiyun.baidu.com/wiki/attach/image/api/imageDownloadAddress?attachId=d3d3973bc6144da6b3e86d761456939f&docGuid=HiC9H1EDbTWpku "")
ä¿®æ”¹åä¿å­˜é€€å‡ºï¼Œç„¶åæ‰§â¾

```
bash qwen2_lora.sh
```
æœåŠ¡è¿â¾æˆåŠŸåï¼Œåœ¨AutoDLå®ä¾‹ä¸­å¯ä»¥é€šè¿‡â¾ƒå®šä¹‰æœåŠ¡è®¿é—®åˆ°webâ»š(è®°å¾—æŠŠä¹‹å‰æ‰“å¼€çš„tensorboardæœåŠ¡å…³æ‰)ï¼Œå•å‡»è·³è½¬åè¿›â¼Šå¦‚ä¸‹æˆªå›¾æ‰€ç¤ºwebæµ‹è¯•â»šâ¾¯

![](https://rte.weiyun.baidu.com/wiki/attach/image/api/imageDownloadAddress?attachId=ee2a8dbbb357406c8592c8b7e08384a0&docGuid=HiC9H1EDbTWpku "")
å¦‚:ç»™æˆ‘æ¨èâ¼€ä¸ªä¸ä½äº1000çš„é…’åº—

![](https://rte.weiyun.baidu.com/wiki/attach/image/api/imageDownloadAddress?attachId=5458ca2d92794f8f82836efaca8a1d9d&docGuid=HiC9H1EDbTWpku "")